{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "\n",
        "# Función para decodificar correos protegidos por Cloudflare\n",
        "def decode_cfemail(cfemail):\n",
        "    r = int(cfemail[:2], 16)\n",
        "    email = ''.join([chr(int(cfemail[i:i+2], 16) ^ r) for i in range(2, len(cfemail), 2)])\n",
        "    return email\n",
        "\n",
        "# URL base con filtros seleccionados\n",
        "url_base = \"https://www.acotur.co/es/directorio?pagina={}&departamentos[]=Caquet%C3%A1&departamentos[]=Huila&departamentos[]=Putumayo&departamentos[]=Tolima\"\n",
        "\n",
        "# Lista para guardar los datos\n",
        "data = []\n",
        "\n",
        "# Recorremos páginas\n",
        "for page in range(1, 10):  # ajusta el rango según el total de páginas\n",
        "    url = url_base.format(page)\n",
        "    print(f\"Scrapeando página {page} -> {url}\")\n",
        "\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        break\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    cards = soup.find_all(\"div\", class_=\"col-md-6 col-lg-4\")\n",
        "    if not cards:\n",
        "        break\n",
        "\n",
        "    for card in cards:\n",
        "        nombre = card.find(\"h5\", class_=\"card-title\").get_text(strip=True) if card.find(\"h5\") else \"\"\n",
        "        ciudad = card.find(\"p\", class_=\"card-text\").get_text(strip=True) if card.find(\"p\") else \"\"\n",
        "\n",
        "        # Enlace al detalle\n",
        "        link_tag = card.find(\"a\", class_=\"btn-ver-mas\")\n",
        "        link = \"https://www.acotur.co\" + link_tag[\"href\"] if link_tag else \"\"\n",
        "\n",
        "        descripcion, categorias, certificaciones, email, redes, rnt = \"\", [], [], \"\", [], \"\"\n",
        "\n",
        "        if link:\n",
        "            detail_response = requests.get(link)\n",
        "            detail_soup = BeautifulSoup(detail_response.text, \"html.parser\")\n",
        "\n",
        "            # Descripción\n",
        "            desc_tag = detail_soup.select_one(\"div.card-body p.card-text\")\n",
        "            descripcion = desc_tag.get_text(\" \", strip=True) if desc_tag else \"\"\n",
        "\n",
        "            # Categorías\n",
        "            categorias = [c.get_text(strip=True) for c in detail_soup.select(\"div.tags-container span.badge.bg-success\")]\n",
        "\n",
        "            # Certificaciones\n",
        "            certificaciones = [c.get_text(strip=True) for c in detail_soup.select(\"div.tags-container span.badge.bg-info\")]\n",
        "\n",
        "            # Email (Cloudflare protegido)\n",
        "            email_tag = detail_soup.find(\"span\", {\"class\": \"__cf_email__\"})\n",
        "            if email_tag and email_tag.has_attr(\"data-cfemail\"):\n",
        "                email = decode_cfemail(email_tag[\"data-cfemail\"])\n",
        "\n",
        "            # Redes sociales\n",
        "            redes = [a[\"href\"] for a in detail_soup.select(\"div.social-links a[href]\")]\n",
        "\n",
        "            # RNT\n",
        "            rnt_tag = detail_soup.select_one(\"p.badge.bg-secondary\")\n",
        "            if rnt_tag:\n",
        "              rnt_text = rnt_tag.get_text(strip=True)\n",
        "              rnt = re.sub(r\"\\D\", \"\", rnt_text)  # deja solo números\n",
        "            else:\n",
        "              rnt = \"\"\n",
        "\n",
        "\n",
        "        data.append({\n",
        "            \"Nombre\": nombre,\n",
        "            \"Ciudad\": ciudad,\n",
        "            \"RNT\": rnt,\n",
        "            \"Descripción\": descripcion,\n",
        "            \"Categorías\": \", \".join(categorias),\n",
        "            \"Certificaciones\": \", \".join(certificaciones),\n",
        "            \"Email\": email,\n",
        "            \"Redes Sociales\": \", \".join(redes),\n",
        "            \"URL\": link\n",
        "        })\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Separar la columna \"Ciudad\" en dos: Ciudad y Departamento\n",
        "df[[\"Ciudad\", \"Departamento\"]] = df[\"Ciudad\"].str.split(\",\", n=1, expand=True)\n",
        "\n",
        "# Quitar espacios extra al inicio o final\n",
        "df[\"Ciudad\"] = df[\"Ciudad\"].str.strip()\n",
        "df[\"Departamento\"] = df[\"Departamento\"].str.strip()\n",
        "\n",
        "# Guardar en CSV\n",
        "df.to_csv(\"acotur_filtros.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"Scraping completado. Archivo guardado como acotur_filtros.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgbIijN2yo8R",
        "outputId": "6986d136-479d-40e8-af8b-2d77a72502e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scrapeando página 1 -> https://www.acotur.co/es/directorio?pagina=1&departamentos[]=Caquet%C3%A1&departamentos[]=Huila&departamentos[]=Putumayo&departamentos[]=Tolima\n",
            "Scrapeando página 2 -> https://www.acotur.co/es/directorio?pagina=2&departamentos[]=Caquet%C3%A1&departamentos[]=Huila&departamentos[]=Putumayo&departamentos[]=Tolima\n",
            "Scrapeando página 3 -> https://www.acotur.co/es/directorio?pagina=3&departamentos[]=Caquet%C3%A1&departamentos[]=Huila&departamentos[]=Putumayo&departamentos[]=Tolima\n",
            "Scrapeando página 4 -> https://www.acotur.co/es/directorio?pagina=4&departamentos[]=Caquet%C3%A1&departamentos[]=Huila&departamentos[]=Putumayo&departamentos[]=Tolima\n",
            "Scrapeando página 5 -> https://www.acotur.co/es/directorio?pagina=5&departamentos[]=Caquet%C3%A1&departamentos[]=Huila&departamentos[]=Putumayo&departamentos[]=Tolima\n",
            "Scraping completado. Archivo guardado como acotur_filtros.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "# Función para normalizar texto (quita tildes y pasa a mayúsculas)\n",
        "def normalizar(texto):\n",
        "    if pd.isna(texto):\n",
        "        return \"\"\n",
        "    texto = texto.strip().upper()\n",
        "    texto = \"\".join(\n",
        "        c for c in unicodedata.normalize(\"NFD\", texto)\n",
        "        if unicodedata.category(c) != \"Mn\"\n",
        "    )\n",
        "    return texto\n",
        "# Normalizar la columna Departamento\n",
        "df[\"Departamento\"] = df[\"Departamento\"].apply(normalizar)\n",
        "\n",
        "# Generar un CSV por cada departamento\n",
        "for depto, datos in df.groupby(\"Departamento\"):\n",
        "    # Crear un nombre de archivo seguro (sin espacios, mayúsculas)\n",
        "    nombre_archivo = f\"{depto.replace(' ', '_').upper()}.csv\"\n",
        "    # Guardar el CSV\n",
        "    datos.to_csv(nombre_archivo, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"Archivo generado: {nombre_archivo}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed9W3WgAa_-u",
        "outputId": "58d5f4f3-3151-4b66-aea3-14c297594d2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo generado: CAQUETA.csv\n",
            "Archivo generado: HUILA.csv\n",
            "Archivo generado: PUTUMAYO.csv\n",
            "Archivo generado: TOLIMA.csv\n"
          ]
        }
      ]
    }
  ]
}